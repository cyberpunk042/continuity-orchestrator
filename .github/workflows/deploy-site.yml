name: Deploy Site

# Build and deploy static site to GitHub Pages
# Triggered ONLY for manual dispatch or template/site code changes
# NOT triggered by state/audit/public changes (cron handles those)

on:
  workflow_dispatch:
    inputs:
      deploy:
        description: 'Deploy to GitHub Pages'
        required: false
        default: 'true'
        type: boolean
  workflow_call:
  push:
    branches: [main]
    paths:
      # Only trigger for code/template changes, NOT state changes
      # Cron workflow handles all automatic deployments
      - 'templates/**'
      - 'src/site/**'
      - 'content/**'
      # Explicitly exclude (cron handles these):
      # - 'state/**'
      # - 'audit/**' 
      # - 'public/**'

# Sets permissions for GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment â€” queue behind renew/cron (never cancel them)
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      # Use minimal Python setup - site generation only needs core deps
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
      
      # Install only what's needed for site generation
      - name: Install minimal dependencies
        run: |
          python -m pip install --upgrade pip --quiet
          pip install pyyaml pydantic jinja2 python-dateutil python-dotenv click cryptography --quiet
          pip install -e . --no-deps --quiet
      
      - name: Build site
        env:
          RENEWAL_TRIGGER_TOKEN: ${{ secrets.RENEWAL_TRIGGER_TOKEN }}
          CONTENT_ENCRYPTION_KEY: ${{ secrets.CONTENT_ENCRYPTION_KEY }}
        run: |
          python -m src.main build-site --output public
      
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public

  deploy:
    if: github.event.inputs.deploy != 'false'
    runs-on: ubuntu-latest
    needs: build
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
      - name: Clear stuck Pages deployments
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Checking for stuck deployments..."
          DEPS=$(gh api "repos/${{ github.repository }}/deployments?environment=github-pages&per_page=5" 2>/dev/null || echo "[]")
          echo "$DEPS" | python3 -c "
          import sys, json, subprocess
          try:
              deps = json.load(sys.stdin)
              if not isinstance(deps, list): deps = []
              for d in deps:
                  dep_id = d.get('id')
                  sha = d.get('sha', '?')[:12]
                  statuses = subprocess.run(
                      ['gh', 'api', f'repos/\${{ github.repository }}/deployments/{dep_id}/statuses'],
                      capture_output=True, text=True, timeout=10
                  )
                  if statuses.returncode == 0:
                      status_list = json.loads(statuses.stdout)
                      latest = status_list[0]['state'] if status_list else 'unknown'
                      if latest in ('in_progress', 'queued', 'waiting', 'pending'):
                          print(f'Clearing stuck deployment {dep_id} (sha:{sha}, state:{latest})')
                          subprocess.run([
                              'gh', 'api', '-X', 'POST',
                              f'repos/\${{ github.repository }}/deployments/{dep_id}/statuses',
                              '-f', 'state=inactive',
                              '-f', 'description=Auto-cleared before new deployment'
                          ], timeout=10)
          except Exception as e: print(f'Cleanup skipped: {e}')
          " || true
          sleep 2

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
      
      # Archive step - archive all key pages if enabled
      - name: Archive to Wayback Machine
        if: vars.ARCHIVE_ENABLED == 'true'
        env:
          ARCHIVE_URL: ${{ vars.ARCHIVE_URL }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          # Determine base URL
          if [ -n "$ARCHIVE_URL" ]; then
            BASE_URL="${ARCHIVE_URL%/}"
          else
            OWNER="${GITHUB_REPOSITORY%/*}"
            REPO="${GITHUB_REPOSITORY#*/}"
            BASE_URL="https://${OWNER}.github.io/${REPO}"
          fi
          
          echo "ðŸ“¦ Archiving site to archive.org..."
          
          # Wait for GitHub Pages propagation
          sleep 10
          
          # Collect URLs to archive from sitemap or fallback list
          URLS=()
          SITEMAP_URL="${BASE_URL}/sitemap.xml"
          SITEMAP=$(curl -s --max-time 10 "$SITEMAP_URL" 2>/dev/null || true)
          
          if echo "$SITEMAP" | grep -q '<loc>'; then
            # Extract URLs from sitemap
            while IFS= read -r loc; do
              URLS+=("$loc")
            done < <(echo "$SITEMAP" | grep -oP '(?<=<loc>)[^<]+')
            echo "  Found ${#URLS[@]} URL(s) from sitemap.xml"
          else
            # Fallback: just the index
            URLS=("${BASE_URL}/")
            echo "  No sitemap found, archiving index only"
          fi
          
          # Submit each URL (best effort, don't fail workflow)
          SUCCESS=0
          TOTAL=${#URLS[@]}
          for URL in "${URLS[@]}"; do
            LABEL="${URL#$BASE_URL/}"
            [ -z "$LABEL" ] && LABEL="index"
            printf "  [%d/%d] %s..." "$((SUCCESS + 1))" "$TOTAL" "$LABEL"
            
            RESULT=$(curl -s -o /dev/null -w "%{http_code}" --max-time 60 \
              -H "User-Agent: Mozilla/5.0" \
              "https://web.archive.org/save/$URL" 2>/dev/null || echo "timeout")
            
            if [ "$RESULT" = "200" ] || [ "$RESULT" = "302" ]; then
              echo " âœ“"
              SUCCESS=$((SUCCESS + 1))
            else
              echo " ($RESULT)"
            fi
            
            # Rate limit: ~3/min for anonymous
            sleep 5
          done
          
          echo "  ðŸ“¦ Archived $SUCCESS/$TOTAL pages"
